The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2025-11-03:10:21:40 INFO     [__main__:446] Selected Tasks: ['mbpp']
2025-11-03:10:21:40 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-11-03:10:21:40 INFO     [evaluator:240] Initializing fast_dllm_v2 model, with arguments: {'model_path':
        '/data/yinghaoliu/Fast-dLLM/models/finetune_fast_dLLM_v2_1.5B/checkpoint-4000', 'show_speed': True}
2025-11-03:10:21:40 INFO     [__main__:446] Selected Tasks: ['mbpp']
2025-11-03:10:21:40 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-11-03:10:21:40 INFO     [evaluator:240] Initializing fast_dllm_v2 model, with arguments: {'model_path':
        '/data/yinghaoliu/Fast-dLLM/models/finetune_fast_dLLM_v2_1.5B/checkpoint-4000', 'show_speed': True}
2025-11-03:10:21:40 INFO     [__main__:446] Selected Tasks: ['mbpp']
2025-11-03:10:21:40 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-11-03:10:21:40 INFO     [evaluator:240] Initializing fast_dllm_v2 model, with arguments: {'model_path':
        '/data/yinghaoliu/Fast-dLLM/models/finetune_fast_dLLM_v2_1.5B/checkpoint-4000', 'show_speed': True}
2025-11-03:10:21:40 INFO     [__main__:446] Selected Tasks: ['mbpp']
2025-11-03:10:21:40 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-11-03:10:21:40 INFO     [evaluator:240] Initializing fast_dllm_v2 model, with arguments: {'model_path':
        '/data/yinghaoliu/Fast-dLLM/models/finetune_fast_dLLM_v2_1.5B/checkpoint-4000', 'show_speed': True}
Generating train split:   0%|          | 0/374 [00:00<?, ? examples/s]Generating train split: 100%|██████████| 374/374 [00:00<00:00, 47278.99 examples/s]
Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 500/500 [00:00<00:00, 110925.21 examples/s]
Generating validation split:   0%|          | 0/90 [00:00<?, ? examples/s]Generating validation split: 100%|██████████| 90/90 [00:00<00:00, 31607.42 examples/s]
Generating prompt split:   0%|          | 0/10 [00:00<?, ? examples/s]Generating prompt split: 100%|██████████| 10/10 [00:00<00:00, 4156.89 examples/s]
2025-11-03:10:21:55 INFO     [evaluator:305] mbpp: Using gen_kwargs: {'until': ['[DONE]'], 'do_sample': False}
2025-11-03:10:21:55 WARNING  [evaluator:324] Overwriting default num_fewshot of mbpp from 3 to 3
2025-11-03:10:21:55 INFO     [api.task:434] Building contexts for mbpp on rank 3...
2025-11-03:10:21:55 INFO     [evaluator:305] mbpp: Using gen_kwargs: {'until': ['[DONE]'], 'do_sample': False}
2025-11-03:10:21:55 WARNING  [evaluator:324] Overwriting default num_fewshot of mbpp from 3 to 3
2025-11-03:10:21:55 INFO     [api.task:434] Building contexts for mbpp on rank 1...
  0%|          | 0/125 [00:00<?, ?it/s]  0%|          | 0/125 [00:00<?, ?it/s]2025-11-03:10:21:55 INFO     [evaluator:305] mbpp: Using gen_kwargs: {'until': ['[DONE]'], 'do_sample': False}
2025-11-03:10:21:55 WARNING  [evaluator:324] Overwriting default num_fewshot of mbpp from 3 to 3
2025-11-03:10:21:55 INFO     [api.task:434] Building contexts for mbpp on rank 2...
2025-11-03:10:21:55 INFO     [evaluator:305] mbpp: Using gen_kwargs: {'until': ['[DONE]'], 'do_sample': False}
2025-11-03:10:21:55 WARNING  [evaluator:324] Overwriting default num_fewshot of mbpp from 3 to 3
2025-11-03:10:21:55 INFO     [api.task:434] Building contexts for mbpp on rank 0...
  0%|          | 0/125 [00:00<?, ?it/s]  0%|          | 0/125 [00:00<?, ?it/s] 15%|█▌        | 19/125 [00:00<00:00, 188.93it/s] 15%|█▌        | 19/125 [00:00<00:00, 188.38it/s] 15%|█▌        | 19/125 [00:00<00:00, 188.47it/s] 15%|█▌        | 19/125 [00:00<00:00, 187.48it/s] 30%|███       | 38/125 [00:00<00:00, 179.73it/s] 30%|███       | 38/125 [00:00<00:00, 178.65it/s] 30%|███       | 38/125 [00:00<00:00, 187.79it/s] 30%|███       | 38/125 [00:00<00:00, 188.09it/s] 46%|████▌     | 57/125 [00:00<00:00, 176.92it/s] 46%|████▋     | 58/125 [00:00<00:00, 183.87it/s] 46%|████▌     | 57/125 [00:00<00:00, 188.02it/s] 46%|████▌     | 57/125 [00:00<00:00, 188.54it/s] 62%|██████▏   | 77/125 [00:00<00:00, 183.33it/s] 62%|██████▏   | 77/125 [00:00<00:00, 184.19it/s] 61%|██████    | 76/125 [00:00<00:00, 188.35it/s] 62%|██████▏   | 77/125 [00:00<00:00, 189.48it/s] 78%|███████▊  | 97/125 [00:00<00:00, 187.07it/s] 78%|███████▊  | 97/125 [00:00<00:00, 186.95it/s] 77%|███████▋  | 96/125 [00:00<00:00, 189.64it/s] 78%|███████▊  | 97/125 [00:00<00:00, 190.04it/s] 93%|█████████▎| 116/125 [00:00<00:00, 187.94it/s] 94%|█████████▎| 117/125 [00:00<00:00, 189.29it/s] 93%|█████████▎| 116/125 [00:00<00:00, 190.36it/s] 94%|█████████▎| 117/125 [00:00<00:00, 190.43it/s]100%|██████████| 125/125 [00:00<00:00, 186.50it/s]
100%|██████████| 125/125 [00:00<00:00, 186.58it/s]
100%|██████████| 125/125 [00:00<00:00, 189.64it/s]
100%|██████████| 125/125 [00:00<00:00, 189.80it/s]
2025-11-03:10:21:56 INFO     [evaluator:574] Running generate_until requests
2025-11-03:10:21:56 INFO     [evaluator:574] Running generate_until requests
2025-11-03:10:21:56 INFO     [evaluator:574] Running generate_until requests
2025-11-03:10:21:56 INFO     [evaluator:574] Running generate_until requests
[rank2]: Traceback (most recent call last):
[rank2]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 434, in <module>
[rank2]:     cli_evaluate()
[rank2]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/__main__.py", line 455, in cli_evaluate
[rank2]:     results = evaluator.simple_evaluate(
[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/utils.py", line 456, in _wrapper
[rank2]:     return fn(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/evaluator.py", line 357, in simple_evaluate
[rank2]:     results = evaluate(
[rank2]:               ^^^^^^^^^
[rank2]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/utils.py", line 456, in _wrapper
[rank2]:     return fn(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/evaluator.py", line 585, in evaluate
[rank2]:     resps = getattr(lm, reqtype)(cloned_reqs)
[rank2]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 327, in generate_until
[rank2]:     reqs_with_indices.sort(key=lambda x: len(x.args))
[rank2]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 327, in <lambda>
[rank2]:     reqs_with_indices.sort(key=lambda x: len(x.args))
[rank2]:                                              ^^^^^^
[rank2]: AttributeError: 'tuple' object has no attribute 'args'
[rank3]: Traceback (most recent call last):
[rank3]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 434, in <module>
[rank3]:     cli_evaluate()
[rank3]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/__main__.py", line 455, in cli_evaluate
[rank3]:     results = evaluator.simple_evaluate(
[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/utils.py", line 456, in _wrapper
[rank3]:     return fn(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/evaluator.py", line 357, in simple_evaluate
[rank3]:     results = evaluate(
[rank3]:               ^^^^^^^^^
[rank3]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/utils.py", line 456, in _wrapper
[rank3]:     return fn(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/evaluator.py", line 585, in evaluate
[rank3]:     resps = getattr(lm, reqtype)(cloned_reqs)
[rank3]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 327, in generate_until
[rank3]:     reqs_with_indices.sort(key=lambda x: len(x.args))
[rank3]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 327, in <lambda>
[rank3]:     reqs_with_indices.sort(key=lambda x: len(x.args))
[rank3]:                                              ^^^^^^
[rank3]: AttributeError: 'tuple' object has no attribute 'args'
[rank1]: Traceback (most recent call last):
[rank1]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 434, in <module>
[rank1]:     cli_evaluate()
[rank1]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/__main__.py", line 455, in cli_evaluate
[rank1]:     results = evaluator.simple_evaluate(
[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/utils.py", line 456, in _wrapper
[rank1]:     return fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/evaluator.py", line 357, in simple_evaluate
[rank1]:     results = evaluate(
[rank1]:               ^^^^^^^^^
[rank1]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/utils.py", line 456, in _wrapper
[rank1]:     return fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/evaluator.py", line 585, in evaluate
[rank1]:     resps = getattr(lm, reqtype)(cloned_reqs)
[rank1]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 327, in generate_until
[rank1]:     reqs_with_indices.sort(key=lambda x: len(x.args))
[rank1]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 327, in <lambda>
[rank1]:     reqs_with_indices.sort(key=lambda x: len(x.args))
[rank1]:                                              ^^^^^^
[rank1]: AttributeError: 'tuple' object has no attribute 'args'
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 434, in <module>
[rank0]:     cli_evaluate()
[rank0]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/__main__.py", line 455, in cli_evaluate
[rank0]:     results = evaluator.simple_evaluate(
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/utils.py", line 456, in _wrapper
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/evaluator.py", line 357, in simple_evaluate
[rank0]:     results = evaluate(
[rank0]:               ^^^^^^^^^
[rank0]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/utils.py", line 456, in _wrapper
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/lm_eval/evaluator.py", line 585, in evaluate
[rank0]:     resps = getattr(lm, reqtype)(cloned_reqs)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 327, in generate_until
[rank0]:     reqs_with_indices.sort(key=lambda x: len(x.args))
[rank0]:   File "/data/yinghaoliu/Fast-dLLM/v2/eval.py", line 327, in <lambda>
[rank0]:     reqs_with_indices.sort(key=lambda x: len(x.args))
[rank0]:                                              ^^^^^^
[rank0]: AttributeError: 'tuple' object has no attribute 'args'
[rank0]:[W1103 10:21:56.938419246 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W1103 10:21:57.842000 2451535 /data/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 2451731 closing signal SIGTERM
W1103 10:21:57.843000 2451535 /data/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 2451734 closing signal SIGTERM
E1103 10:21:58.022000 2451535 /data/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 1 (pid: 2451732) of binary: /home/yinghaoliu/anaconda3/envs/gla-dllm/bin/python3.11
Traceback (most recent call last):
  File "/home/yinghaoliu/anaconda3/envs/gla-dllm/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1226, in launch_command
    multi_gpu_launcher(args)
  File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/torch/distributed/run.py", line 927, in run
    elastic_launch(
  File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 156, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yinghaoliu/anaconda3/envs/gla-dllm/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 293, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
eval.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-11-03_10:21:57
  host      : hustvl-2023
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 2451733)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-03_10:21:57
  host      : hustvl-2023
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 2451732)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
